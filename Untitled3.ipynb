{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bbe56-8aae-49fd-8873-1838856183e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 02:14:23.375705: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-14 02:14:24.127445: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-14 02:14:24.127489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-14 02:14:24.274593: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-14 02:14:24.506973: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-14 02:14:26.106845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-04-14 02:14:29.914848: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:14:30.321906: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:14:30.321948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  1-10 RANGE TRAINING\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, MaxPooling2D,Conv2D,Add, Dense, Flatten, Dropout, GlobalAveragePooling1D, Multiply, BatchNormalization, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras.metrics import AUC, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "#import seaborn as sns\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from keras.layers import Reshape\n",
    "# Assuming each image is 256x256 pixels with 3 color channels (RGB)\n",
    "input_shape = (256, 256, 3)\n",
    "num_outputs = 5  # 1 for the number of axes + 5 for the attribute values\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# Define dataset paths\n",
    "dataset_paths = [\n",
    "    r\"extracted_data/FinalDatasetwithrangefix\",\n",
    "    r\"extracted_data/radarcharts_geridvaluesnofilllineentity2\",\n",
    "    r\"extracted_data/radarchart_with_linestar2\",\n",
    "    r\"extracted_data/radarcharts_equilateralpygal\",\n",
    "    r\"extracted_data/radarcharts_equilateral\"\n",
    "]\n",
    "\n",
    "# Load metadata for all datasets\n",
    "# Load metadata for all datasets\n",
    "metadata_list = []\n",
    "for dataset_path in dataset_paths:\n",
    "    metadata_path = os.path.join(dataset_path, \"metadata.json\")\n",
    "    with open(metadata_path, 'r') as json_file:\n",
    "        metadata_list.append(json.load(json_file)['data'])\n",
    "\n",
    "\n",
    "print(metadata_list)\n",
    "# Initialize lists to store data and labels\n",
    "data = []\n",
    "labels = []\n",
    "max_length = 0\n",
    "\n",
    "# Function to extract SIFT features\n",
    "def extract_sift_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# Load dataset and preprocess labels\n",
    "for metadata, dataset_path in zip(metadata_list, dataset_paths):\n",
    "    for item in metadata:\n",
    "        image_name = item['Image Name']\n",
    "        image_path = os.path.join(dataset_path, image_name)\n",
    "        image = load_img(image_path, target_size=(256, 256))\n",
    "        image = np.array(image) \n",
    "        # Extract SIFT features\n",
    "        keypoints, descriptors = extract_sift_features(image)\n",
    "\n",
    "        # Create feature vector from SIFT descriptors\n",
    "        if descriptors is not None:\n",
    "            feature_vector = descriptors.flatten()\n",
    "\n",
    "            # Update the maximum length\n",
    "            max_length = max(max_length, len(feature_vector))\n",
    "\n",
    "            # Append the feature vector and label to the lists\n",
    "            data.append(feature_vector)\n",
    "\n",
    "            # Determine the number of axes\n",
    "            num_axes = len(item['Attribute Data'])\n",
    "            attribute_values = [attr['Value'] for attr in item['Attribute Data']]\n",
    "\n",
    "            label = attribute_values + [0] * (5 - num_axes)\n",
    "            labels.append(label)\n",
    "\n",
    "# Pad the feature vectors to the maximum length\n",
    "data_padded = []\n",
    "for feature_vector in data:\n",
    "    padded_feature_vector = np.pad(feature_vector, (0, max_length - len(feature_vector)), mode='constant')\n",
    "    data_padded.append(padded_feature_vector)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data = np.array(data_padded)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Now, let's check and potentially fix issues:\n",
    "# 1. Check the length of feature vectors to ensure they are consistent\n",
    "# 2. Verify the dimensionality of the label vectors (5 for each label)\n",
    "# 3. If there are inconsistencies, debug the extraction process and ensure correct processing\n",
    "\n",
    "# Check the length of feature vectors\n",
    "print(\"Length of feature vectors:\", len(data[0]))  # Assuming all feature vectors have the same length\n",
    "\n",
    "# Check the dimensionality of label vectors\n",
    "print(\"Dimensionality of label vectors:\", labels.shape[1])\n",
    "\n",
    "# If there are any issues, inspect the data and labels to identify and fix the root cause\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.67, random_state=42)\n",
    "\n",
    "# Check the length of data and labels\n",
    "print(f\"Length of data: {len(data)}\")\n",
    "print(f\"Length of labels: {len(labels)}\")  # Corrected from preprocessed_labels to labels\n",
    "# Check the shapes of the splits\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Testing data shape: {x_test.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Testing labels shape: {y_test.shape}\")\n",
    "\n",
    "def create_attention_module(feature_map, input_channels, ratio=8):\n",
    "    # Check the shape of the feature_map tensor\n",
    "    print(\"Shape of feature_map:\", feature_map.shape)\n",
    "\n",
    "    # Ensure the feature_map tensor has the expected shape\n",
    "    expected_shape = (None, None, 3)\n",
    "    assert feature_map.shape[1:] == expected_shape, f\"Unexpected shape. Expected: {expected_shape}, Got: {feature_map.shape[1:]}\"\n",
    "\n",
    "    # Global average pooling along spatial dimensions\n",
    "    squeeze = tf.reduce_mean(feature_map, axis=[1, 2], keepdims=True)\n",
    "\n",
    "    # Excitation mechanism\n",
    "    excitation = Dense(units=input_channels // ratio, activation='relu')(squeeze)\n",
    "    excitation = Dense(units=input_channels, activation='sigmoid')(excitation)\n",
    "\n",
    "    # Reshape excitation to have the same shape as feature_map\n",
    "    excitation = tf.image.resize(excitation, tf.shape(feature_map)[1:3])\n",
    "\n",
    "    # Scale the input feature map\n",
    "    scaled_feature_map = tf.multiply(feature_map, excitation)\n",
    "\n",
    "    return scaled_feature_map\n",
    "\n",
    "\n",
    "def build_cnn_with_attention(input_shape, num_outputs, x_train, y_train):\n",
    "    # Define input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    print(\"Shape of input_layer:\", input_layer.shape)\n",
    "    # Apply attention mechanism to input descriptors\n",
    "    #attention_layer = create_attention_module(input_layer, input_channels=input_shape[0])\n",
    "\n",
    "    # Residual connection\n",
    "    #residual_layer = Add()([input_layer, attention_layer])\n",
    "\n",
    "    # Continue from the residual layer\n",
    "    \n",
    "\n",
    "    # Hidden layers\n",
    "    x = Dense(512, activation='relu')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(input_layer)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Dense(num_outputs)(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Assuming each image is 256x256 pixels with 3 color channels (RGB)\n",
    "input_shape = (40448,)\n",
    "\n",
    "num_outputs = 5  # 1 for the number of axes + 5 for the attribute values\n",
    "\n",
    "# Build the model\n",
    "# Build the model\n",
    "cnn_model = build_cnn_with_attention(input_shape, num_outputs, x_train, y_train)\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_checkpoint = ModelCheckpoint('best_model_datavalue.h5', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.006)\n",
    "tensorboard = TensorBoard(log_dir='./logs')  # Assuming TensorBoard logs are stored in ./logs\n",
    "\n",
    "# Summary of the model\n",
    "cnn_model.summary()\n",
    "\n",
    "# Fit the model with these variables for the corresponding outputs\n",
    "history = cnn_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, model_checkpoint, reduce_lr, tensorboard]\n",
    ")\n",
    "\n",
    "# Load best model and evaluate\n",
    "cnn_model.load_weights('best_model_datavalue.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = cnn_model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Optionally, visualize the predictions vs. actual values\n",
    "predictions = cnn_model.predict(x_test)\n",
    "for i in range(min(len(predictions), 10)):  # Visualize first 10 predictions\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {predictions[i]}\")\n",
    "\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(range(len(y_test)), y_test[:, i], color='blue', label='Actual')\n",
    "    plt.scatter(range(len(predictions)), predictions[:, i], color='red', label='Predicted', alpha=0.5)\n",
    "    plt.title(f'Actual vs Predicted for Output {i+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate errors\n",
    "errors = predictions - y_test\n",
    "\n",
    "# Plotting the distribution of errors for each output\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(errors[:, i], kde=True)\n",
    "    plt.title(f'Error Distribution for Output {i+1}')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# When you need to use the scaler in the future\n",
    "#scaler = joblib.load('minmax_scaler.joblib')\n",
    "# Plot training and validation loss over epochs\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Scatter plot of actual vs. predicted values for each output\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(range(len(y_test)), y_test[:, i], color='blue', label='Actual')\n",
    "    plt.scatter(range(len(predictions)), predictions[:, i], color='red', label='Predicted', alpha=0.5)\n",
    "    plt.plot(range(len(predictions)), predictions[:, i], color='green', linestyle='--', label='Predicted Line')\n",
    "    plt.title(f'Actual vs Predicted for Output {i+1}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate errors\n",
    "errors = predictions - y_test\n",
    "\n",
    "# Plotting the distribution of errors for each output\n",
    "for i in range(num_outputs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(errors[:, i], kde=True)\n",
    "    plt.title(f'Error Distribution for Output {i+1}')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34341dd1-45ea-47a0-afd7-fe9ce6c8ac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 02:23:44.988013: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-14 02:23:45.674467: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-14 02:23:45.674512: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-14 02:23:45.794549: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-14 02:23:46.036573: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-14 02:23:47.568312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-04-14 02:23:51.519125: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:51.932065: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:51.932112: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:51.933918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:51.933953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:51.933970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:52.079632: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:52.079690: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:52.079697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-14 02:23:52.079727: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-14 02:23:52.079745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6085 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, MaxPooling2D,Conv2D,Add, Dense, Flatten, Dropout, GlobalAveragePooling2D, Multiply, BatchNormalization, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras.applications import VGG16,ResNet50\n",
    "from tensorflow.keras.metrics import AUC, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "#from keras.applications import VGG19\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "# Function to extract SIFT features\n",
    "def extract_sift_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    return descriptors.flatten() if descriptors is not None else np.zeros((128,))\n",
    "\n",
    "# Load metadata for all datasets\n",
    "dataset_paths = [\n",
    "    r\"extracted_data/FinalDatasetwithrangefix\",\n",
    "    r\"extracted_data/radarcharts_equilateral\"\n",
    "]\n",
    "\n",
    "metadata_list = []\n",
    "for dataset_path in dataset_paths:\n",
    "    metadata_path = os.path.join(dataset_path, \"metadata.json\")\n",
    "    with open(metadata_path, 'r') as json_file:\n",
    "        metadata_list.append(json.load(json_file)['data'])\n",
    "\n",
    "# Initialize lists to store data and labels\n",
    "data_sift = []\n",
    "data_resnet = []\n",
    "labels = []\n",
    "max_length_sift = 128  # Assuming SIFT feature length is 128\n",
    "input_shape_resnet = (150, 150, 3)  # Input size for ResNet\n",
    "\n",
    "# Load pre-trained ResNet without top layers\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape_resnet)\n",
    "\n",
    "# Freeze the layers of the ResNet model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Extract SIFT features and preprocess images for ResNet\n",
    "for metadata, dataset_path in zip(metadata_list, dataset_paths):\n",
    "    for item in metadata:\n",
    "        image_name = item['Image Name']\n",
    "        image_path = os.path.join(dataset_path, image_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = load_img(image_path, target_size=(input_shape_resnet[0], input_shape_resnet[1]))\n",
    "        image_resnet = img_to_array(image)\n",
    "        image_resnet = image_resnet.astype(np.uint8)\n",
    "        # Preprocess image for ResNet\n",
    "        image_resnet = tf.keras.applications.resnet50.preprocess_input(image_resnet)\n",
    "        \n",
    "        # Extract SIFT features\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        sift_features = extract_sift_features(image_bgr)\n",
    "        \n",
    "        # Update the maximum length for SIFT features\n",
    "        max_length_sift = max(max_length_sift, len(sift_features))\n",
    "        \n",
    "        # Append the features and label to the lists\n",
    "        data_resnet.append(image_resnet)\n",
    "        data_sift.append(sift_features)\n",
    "        \n",
    "        # Determine the number of axes\n",
    "        num_axes = len(item['Attribute Data'])\n",
    "        attribute_values = [attr['Value'] for attr in item['Attribute Data']]\n",
    "        label = attribute_values + [0] * (5 - num_axes)\n",
    "        labels.append(label)\n",
    "\n",
    "# Pad the SIFT feature vectors to the maximum length\n",
    "data_sift_padded = []\n",
    "for feature_vector in data_sift:\n",
    "    padded_feature_vector = np.pad(feature_vector, (0, max_length_sift - len(feature_vector)), mode='constant')\n",
    "    data_sift_padded.append(padded_feature_vector)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data_resnet = np.array(data_resnet)\n",
    "data_sift_padded = np.array(data_sift_padded)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets\n",
    "x_train_resnet, x_temp_resnet, x_train_sift, x_temp_sift, y_train, y_temp = train_test_split(\n",
    "    data_resnet, data_sift_padded, labels, test_size=0.3, random_state=42)\n",
    "x_val_resnet, x_test_resnet, x_val_sift, x_test_sift, y_val, y_test = train_test_split(\n",
    "    x_temp_resnet, x_temp_sift, y_temp, test_size=0.67, random_state=42)\n",
    "\n",
    "# Define input layers\n",
    "input_layer_resnet = Input(shape=input_shape_resnet, name='input_resnet')\n",
    "input_layer_sift = Input(shape=(max_length_sift,), name='input_sift')\n",
    "\n",
    "# Pass images through ResNet model\n",
    "resnet_features = resnet_model(input_layer_resnet)\n",
    "\n",
    "# Concatenate ResNet features with SIFT features\n",
    "concatenated_features = Concatenate()([resnet_features, input_layer_sift])\n",
    "\n",
    "# Add additional layers for classification or regression\n",
    "x = Dense(512, activation='relu')(concatenated_features)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(5, activation='linear')(x)  # Assuming 5 output dimensions\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[input_layer_resnet, input_layer_sift], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [x_train_resnet, x_train_sift],\n",
    "    y_train,\n",
    "    validation_data=([x_val_resnet, x_val_sift], y_val),\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5),\n",
    "               ModelCheckpoint('best_model.h5', save_best_only=True),\n",
    "               ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.006)]\n",
    ")\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_weights('best_model.h5')\n",
    "loss, mae = model.evaluate([x_test_resnet, x_test_sift], y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f5068e-94ce-49d3-9148-7a0160c4bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:56:54.809282: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-15 00:56:55.555182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-15 00:56:55.555228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-15 00:56:55.671599: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-15 00:56:55.909796: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 00:56:57.549468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-04-15 00:57:01.456549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:01.869022: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:01.869062: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:01.871526: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:01.871586: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:01.871607: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:02.037763: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:02.037821: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:02.037828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-15 00:57:02.037858: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 00:57:02.037877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6085 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [112256], output_shape = [7, 7, 112256, 1]\n\nCall arguments received by layer \"reshape\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 112256), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 161\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Train the model in batches\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m batch_size:\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length_sift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    163\u001b[0m     labels \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m, in \u001b[0;36mprocess_batch\u001b[0;34m(data_batch, labels_batch, max_length_sift)\u001b[0m\n\u001b[1;32m     56\u001b[0m     resnet_features \u001b[38;5;241m=\u001b[39m resnet_model(input_layer_resnet)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Reshape the SIFT features to match the spatial dimensions of the ResNet features\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     input_layer_sift_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length_sift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer_sift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Flatten ResNet features\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     flattened_resnet_features \u001b[38;5;241m=\u001b[39m Flatten()(resnet_features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/reshape.py:118\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    116\u001b[0m     output_shape[unknown] \u001b[38;5;241m=\u001b[39m original \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m known\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original \u001b[38;5;241m!=\u001b[39m known:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_shape\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [112256], output_shape = [7, 7, 112256, 1]\n\nCall arguments received by layer \"reshape\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 112256), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Reshape\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, MaxPooling2D,Conv2D,Add, Dense, Flatten, Dropout, GlobalAveragePooling2D, Multiply, BatchNormalization, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras.applications import VGG16,ResNet50\n",
    "from tensorflow.keras.metrics import AUC, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n",
    "#from keras.applications import VGG19\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "# Function to extract SIFT features\n",
    "def extract_sift_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    return descriptors.flatten() if descriptors is not None else np.zeros((128,))\n",
    "\n",
    "# Pad SIFT feature vectors to a fixed length\n",
    "def pad_sift_features(features, max_length):\n",
    "    padded_features = np.zeros((max_length,))\n",
    "    padded_features[:min(len(features), max_length)] = features[:max_length]\n",
    "    return padded_features\n",
    "\n",
    "# Define function to process each batch\n",
    "def process_batch(data_batch, labels_batch, max_length_sift):\n",
    "    # Split the data batch into ResNet and SIFT features\n",
    "    data_resnet = np.array([item[0] for item in data_batch])\n",
    "    data_sift = np.array([pad_sift_features(item[1], max_length_sift) for item in data_batch])\n",
    "    labels = np.array(labels_batch)\n",
    "    \n",
    "    # Split the data into training, validation, and testing sets\n",
    "    x_train_resnet, x_temp_resnet, x_train_sift, x_temp_sift, y_train, y_temp = train_test_split(\n",
    "        data_resnet, data_sift, labels, test_size=0.3, random_state=42)\n",
    "    x_val_resnet, x_test_resnet, x_val_sift, x_test_sift, y_val, y_test = train_test_split(\n",
    "        x_temp_resnet, x_temp_sift, y_temp, test_size=0.67, random_state=42)\n",
    "    \n",
    "    # Define input layers\n",
    "    input_layer_resnet = Input(shape=input_shape_resnet, name='input_resnet')\n",
    "    input_layer_sift = Input(shape=(max_length_sift,), name='input_sift')\n",
    "    \n",
    "    # Pass images through ResNet model\n",
    "    resnet_features = resnet_model(input_layer_resnet)\n",
    "    \n",
    "# Reshape the SIFT features to match the spatial dimensions of the ResNet features\n",
    "    input_layer_sift_reshaped = Reshape((7, 7, max_length_sift, 1))(input_layer_sift)\n",
    "\n",
    "# Flatten ResNet features\n",
    "    flattened_resnet_features = Flatten()(resnet_features)\n",
    "\n",
    "# Concatenate ResNet features with SIFT features\n",
    "    concatenated_features = Concatenate()([flattened_resnet_features, input_layer_sift_reshaped])\n",
    "\n",
    "\n",
    "    # Add additional layers for classification or regression\n",
    "    x = Dense(512, activation='relu')(concatenated_features)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output_layer = Dense(5, activation='linear')(x)  # Assuming 5 output dimensions\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[input_layer_resnet, input_layer_sift], outputs=output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        [x_train_resnet, x_train_sift],\n",
    "        y_train,\n",
    "        validation_data=([x_val_resnet, x_val_sift], y_val),\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5),\n",
    "                   ModelCheckpoint('best_model.h5', save_best_only=True),\n",
    "                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.006)]\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    model.load_weights('best_model.h5')\n",
    "    loss, mae = model.evaluate([x_test_resnet, x_test_sift], y_test)\n",
    "    print(f\"Test Loss: {loss}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Load metadata for all datasets\n",
    "dataset_paths = [\n",
    "    r\"extracted_data/FinalDatasetwithrangefix\",\n",
    "    r\"extracted_data/radarcharts_equilateral\"\n",
    "]\n",
    "\n",
    "metadata_list = []\n",
    "for dataset_path in dataset_paths:\n",
    "    metadata_path = os.path.join(dataset_path, \"metadata.json\")\n",
    "    with open(metadata_path, 'r') as json_file:\n",
    "        metadata_list.append(json.load(json_file)['data'])\n",
    "\n",
    "# Initialize lists to store data and labels\n",
    "data = []\n",
    "labels = []\n",
    "max_length_sift = 128  # Assuming SIFT feature length is 128\n",
    "input_shape_resnet = (224, 224, 3)  # Input size for ResNet\n",
    "\n",
    "# Load pre-trained ResNet without top layers\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape_resnet)\n",
    "\n",
    "# Freeze the layers of the ResNet model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Process data in batches\n",
    "batch_size = 32\n",
    "for metadata, dataset_path in zip(metadata_list, dataset_paths):\n",
    "    for item in metadata:\n",
    "        image_name = item['Image Name']\n",
    "        image_path = os.path.join(dataset_path, image_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = load_img(image_path, target_size=(input_shape_resnet[0], input_shape_resnet[1]))\n",
    "        image_resnet = img_to_array(image)\n",
    "        image_resnet = image_resnet.astype(np.uint8)\n",
    "        # Preprocess image for ResNet\n",
    "        image_resnet = tf.keras.applications.resnet50.preprocess_input(image_resnet)\n",
    "        \n",
    "        # Extract SIFT features\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        sift_features = extract_sift_features(image_bgr)\n",
    "        \n",
    "        # Update the maximum length for SIFT features\n",
    "        max_length_sift = max(max_length_sift, len(sift_features))\n",
    "        \n",
    "        # Append the features and label to the lists\n",
    "        data.append((image_resnet, sift_features))\n",
    "        \n",
    "        # Determine the number of axes\n",
    "        num_axes = len(item['Attribute Data'])\n",
    "        attribute_values = [attr['Value'] for attr in item['Attribute Data']]\n",
    "        label = attribute_values + [0] * (5 - num_axes)\n",
    "        labels.append(label)\n",
    "        \n",
    "        # Train the model in batches\n",
    "        if len(data) == batch_size:\n",
    "            process_batch(data, labels, max_length_sift)\n",
    "            data = []\n",
    "            labels = []\n",
    "\n",
    "# If there are remaining data in the last batch, process it\n",
    "if data:\n",
    "    process_batch(data, labels, max_length_sift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7602cb9f-bb8f-4f3a-8d46-33160c403f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 01:14:21.276321: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-15 01:14:21.996330: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-15 01:14:21.996376: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-15 01:14:22.118082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-15 01:14:22.351890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 01:14:23.982347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-04-15 01:14:27.978184: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.430721: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.430766: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.433006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.433064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.433086: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.583229: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.583291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.583298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-15 01:14:28.583329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-15 01:14:28.583347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6085 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:04:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_resnet (InputLayer)   [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " resnet50 (Functional)       (None, 7, 7, 2048)           2358771   ['input_resnet[0][0]']        \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 100352)               0         ['resnet50[0][0]']            \n",
      "                                                                                                  \n",
      " input_sift (InputLayer)     [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 100480)               0         ['flatten[0][0]',             \n",
      "                                                                     'input_sift[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  5144627   ['concatenate[0][0]']         \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 512)                  2048      ['dense[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 256)                  1024      ['dense_1[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 5)                    1285      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 75169669 (286.75 MB)\n",
      "Trainable params: 51580421 (196.76 MB)\n",
      "Non-trainable params: 23589248 (89.99 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_val_resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 131\u001b[0m\n\u001b[1;32m    124\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m data_generator(metadata_list, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m    127\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    128\u001b[0m     train_generator,\n\u001b[1;32m    129\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39msteps_per_epoch,\n\u001b[1;32m    130\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m--> 131\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m([\u001b[43mx_val_resnet\u001b[49m, x_val_sift], y_val),\n\u001b[1;32m    132\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m    133\u001b[0m                ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    134\u001b[0m                ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.006\u001b[39m)]\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Load best model and evaluate\u001b[39;00m\n\u001b[1;32m    138\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_val_resnet' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Reshape\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, AveragePooling2D, MaxPooling2D,Conv2D,Add, Dense, Flatten, Dropout, GlobalAveragePooling2D, Multiply, BatchNormalization, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
    "from tensorflow.keras.applications import VGG16,ResNet50\n",
    "from tensorflow.keras.metrics import AUC, MeanAbsoluteError\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n",
    "#from keras.applications import VGG19\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Function to extract SIFT features\n",
    "def extract_sift_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    return descriptors.flatten() if descriptors is not None else np.zeros((128,))\n",
    "\n",
    "# Load metadata for all datasets\n",
    "dataset_paths = [\n",
    "    r\"extracted_data/FinalDatasetwithrangefix\",\n",
    "\n",
    "    r\"extracted_data/radarcharts_equilateral\"\n",
    "]\n",
    "# Generator function to load and preprocess images in batches\n",
    "def data_generator(metadata_list, batch_size=16):\n",
    "    while True:\n",
    "        data_resnet = []\n",
    "        data_sift = []\n",
    "        labels = []\n",
    "        for metadata in metadata_list:\n",
    "            for item in metadata:\n",
    "                image_name = item['Image Name']\n",
    "                image_path = os.path.join(dataset_path, image_name)\n",
    "                image = load_img(image_path, target_size=(224, 224))\n",
    "                image_resnet = img_to_array(image)\n",
    "                image_resnet = image_resnet.astype(np.uint8)\n",
    "                image_resnet = tf.keras.applications.resnet50.preprocess_input(image_resnet)\n",
    "                image_bgr = cv2.imread(image_path)\n",
    "                sift_features = extract_sift_features(image_bgr)\n",
    "                data_resnet.append(image_resnet)\n",
    "                data_sift.append(sift_features)\n",
    "                num_axes = len(item['Attribute Data'])\n",
    "                attribute_values = [attr['Value'] for attr in item['Attribute Data']]\n",
    "                label = attribute_values + [0] * (5 - num_axes)\n",
    "                labels.append(label)\n",
    "                if len(data_resnet) == batch_size:\n",
    "                    padded_sift_features = pad_sequences(data_sift, maxlen=128, dtype='float32', padding='post')\n",
    "                    yield [np.array(data_resnet), padded_sift_features], np.array(labels)\n",
    "                    data_resnet = []\n",
    "                    data_sift = []\n",
    "                    labels = []\n",
    "\n",
    "# Load metadata for all datasets\n",
    "dataset_paths = [\n",
    "    r\"extracted_data/FinalDatasetwithrangefix\",\n",
    "\n",
    "    r\"extracted_data/radarcharts_equilateral\"\n",
    "]\n",
    "\n",
    "metadata_list = []\n",
    "for dataset_path in dataset_paths:\n",
    "    metadata_path = os.path.join(dataset_path, \"metadata.json\")\n",
    "    with open(metadata_path, 'r') as json_file:\n",
    "        metadata_list.append(json.load(json_file)['data'])\n",
    "\n",
    "# Load pre-trained ResNet without top layers\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the ResNet model\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define input layers\n",
    "input_layer_resnet = Input(shape=(224, 224, 3), name='input_resnet')\n",
    "input_layer_sift = Input(shape=(128,), name='input_sift')\n",
    "\n",
    "# Pass images through ResNet model\n",
    "resnet_features = resnet_model(input_layer_resnet)\n",
    "\n",
    "# Flatten the ResNet features\n",
    "flattened_resnet_features = Flatten()(resnet_features)\n",
    "\n",
    "# Concatenate ResNet features with SIFT features\n",
    "concatenated_features = Concatenate()([flattened_resnet_features, input_layer_sift])\n",
    "\n",
    "# Add additional layers for classification or regression\n",
    "x = Dense(512, activation='relu')(concatenated_features)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(5, activation='linear')(x)  # Assuming 5 output dimensions\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[input_layer_resnet, input_layer_sift], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train the model using the generator function\n",
    "batch_size = 16\n",
    "steps_per_epoch = sum(len(metadata) for metadata in metadata_list) // batch_size\n",
    "train_generator = data_generator(metadata_list, batch_size=batch_size)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=100,\n",
    "    validation_data=([x_val_resnet, x_val_sift], y_val),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=5),\n",
    "               ModelCheckpoint('best_model.h5', save_best_only=True),\n",
    "               ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.006)]\n",
    ")\n",
    "\n",
    "# Load best model and evaluate\n",
    "model.load_weights('best_model.h5')\n",
    "loss, mae = model.evaluate([x_test_resnet, x_test_sift], y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b00fc6-5eb5-44ed-b2e5-af2ea8175af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60152a8a-55e5-4fdc-a779-f7148fcd1161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
